{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexpress\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpx\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fashion_mnist\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_catagorical\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.utils import to_catagorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, comfusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "sns.set.style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(np.unique(y_train))\n",
    "n_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer = 15\n",
    "\n",
    "print(F\"array pointer = {pointer}\")\n",
    "print(F\"x_train[{pointer}] shape: {X_train[pointer].shape}\")\n",
    "print(f\"label: {y_train[pointer]}\")\n",
    "\n",
    "plt.imshow(X_train[pointer],cmap='accent')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_images(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    check images for:\n",
    "    * being an array\n",
    "    * shape (28x28)\n",
    "    * colour channel values\n",
    "    * NaN values\n",
    "    \"\"\"\n",
    "    invalid_count = 0\n",
    "    valid_count = 0\n",
    "\n",
    "    for idx, image in enumerate(dataset):\n",
    "        if not isinstance(image, np.ndarray):\n",
    "            print(F\"{dataset_name} - Index {idk}: Not a valid image array\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        if image.shape !=(28x28):\n",
    "            print(f\"{dataset_name} - Index {idx}: Incorrect shape {image.shape}\")\n",
    "            invalid_count +=1\n",
    "            continue\n",
    "\n",
    "        if not (image.dtype == np.uint8 and image.min() >= 0 and image.max() <= 255):\n",
    "            print(f\"{dataset_name} - Index {idx}: Invalid pixel values (Min: {image.min()}, Max: {image.max()})\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        if np.isnan(image).any():\n",
    "            print(f\"{dataset_name} - Index {idx}: Contains NaN values\")\n",
    "            invalid_count += 1\n",
    "            continue\n",
    "\n",
    "        valid_count += 1\n",
    "\n",
    "    print(f\"\\n{dataset_name}: {valid_count} valid images, {invalid_count} invalid images\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking Images...\\n\")\n",
    "check_images(X_train, \"Train\")\n",
    "check_images(X_test, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "                                    X_train,\n",
    "                                    y_train,\n",
    "                                    test_size=0.2,\n",
    "                                    random_state=0\n",
    ")\n",
    "\n",
    "print(\"* Train set:\", X_train.shape, y_train.shape)\n",
    "print(\"* Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"* Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trousers\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_labels(dataset, dataset_name):\n",
    "    \"\"\"\n",
    "    Helper function to count occurrences of each ;abel and print them\n",
    "    \"\"\"\n",
    "    global df_freq\n",
    "    unique, counts = np.unique(dataset, return_counts=True)\n",
    "    for label, frequency in zip(unique, counts):\n",
    "        df_freq = pd.concat([df.freq, pd.DataFrame([{'set': dataset_name, 'Label': class_names[label], 'Frequency': frequency}])], ignore_index=True)\n",
    "        print(f\"* {dataset_name} - {class_names[label]}: {frequency} images\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels(y_train, \"Train\")\n",
    "count_labels(y_test, \"Test\")\n",
    "count_labels(y_val, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_freq, x='Set', y='Freqency', hue='Label')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Label Frequency Distribution in Train, Validation, and Test Sets\")\n",
    "plt.savefig(\"/workspaces/m32895-coursework-2025/outputs/distribution_in_sets.png\", bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X_train = \u001b[43mX_train\u001b[49m.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[32m255.0\u001b[39m\n\u001b[32m      2\u001b[39m X_val = X_val.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[32m255.0\u001b[39m\n\u001b[32m      3\u001b[39m X_test = X_test.astype(\u001b[33m\"\u001b[39m\u001b[33mfloat32\u001b[39m\u001b[33m\"\u001b[39m) / \u001b[32m255.0\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val = X_val.astype(\"float32\") / 255.0\n",
    "X_test = X_test.astype(\"float32\") / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = 10\n",
    "y_train = to_categorical(y_train, num_classes=n_labels)\n",
    "y_val = to_categorical(y_val, num_classes=n_labels)\n",
    "y_test = to_categorical(y_test, num_classes=n_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43my_test\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tf_model(input_shape, n_labels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv(filters=16, kernal_size=(3,3), input_shape=input_shape, activation='relu',))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv(filters=16, kernal_size=(3,3), activation='relu',))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(n_labels, activation='softmax'))\n",
    "    model.compile(Loss='catagorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeel = build_tf_model(input_shape=X_train.shape[1], n_labels=n_labels )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_tf_model(input_shape= X_train.shape[1:], n_labels=n_labels )\n",
    "\n",
    "model.fir(x=X_train,\n",
    "          y=y_train,\n",
    "          epochs=4,\n",
    "          validation_data=(X_val, y_val),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.DatFrame(model.history.history)\n",
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "history[['loss','val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "history[['accuracy','val_accuracy']].plot(style='.-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_and_report(X,y,pipeline,Label_map):\n",
    "    \"\"\"\n",
    "    Print confusion matrix and report\n",
    "    \"\"\"\n",
    "    prediction = pipeline.predict(X)\n",
    "    prediction = np.argmax(prediction, axis=1)\n",
    "\n",
    "    y = np.argmax(y, axis=1)\n",
    "\n",
    "    print('--- Confusion Matrix ---')\n",
    "    print(pd.DataFrame(confusion_matrix(y_true=preduction, y_pred=y),\n",
    "                       columns=[ [\"Actual \" + sub for sun in label_map] ],\n",
    "                       index= [ [\"Prediction \" + sub for sub in label_map ]]\n",
    "    ))\n",
    "print(\"\\n\")\n",
    "\n",
    "print('--- Classification Report ---')\n",
    "print(classification_report(y, predction, target_names=label_map),\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_performance(X_train, y_train, X_test, y_test, X_val, y_val, pipeline, Label_map):\n",
    "    \"\"\"\n",
    "    Print classification performance\n",
    "    \"\"\"\n",
    "    print(\"#### Train Set ###\\n\")\n",
    "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Validation Set ###\\n\")\n",
    "    confusion_matrix_and_report(X_val, y_val, pipeline, label_map)\n",
    "\n",
    "    print(\"#### Test Set ###\\n\")\n",
    "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_performance(X_train, y_train,\n",
    "                    X_test, y_test,\n",
    "                    X_val, y_val, \n",
    "                    model,\n",
    "                    Label_map= class_names\n",
    "                    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
